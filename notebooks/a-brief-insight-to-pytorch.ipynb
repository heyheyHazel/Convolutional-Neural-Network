{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 一、torch.nn类的Container\n### 1.nn.Module\ntorch.nn.Module是PyTorch中所有神经网络模块的基类，任何自定义的网络结构、层等都需要继承这个类。其核心用途如下：\n\n- **层次化结构**：模块可以包含子模块，从而构建复杂的网络结构（如将多个层组合成一个模块，然后再组合成整个网络）。\n- **计算图支持**：定义前向传播（forward）方法后，PyTorch会自动跟踪计算图，支持自动求导。\n- **参数管理**：模块可以跟踪其内部的所有nn.Parameter对象（通过parameters()方法访问），方便优化器的使用。\n- **状态管理**：提供了将模型参数移动到GPU（.to(device)）、保存模型（state_dict）和加载模型（load_state_dict）的功能。","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# 自定义神经网络模型Model，继承nn.Module的模版\nclass Model(nn.Module):\n\n    # 定义初始化函数，神经网络结构\n    def __init__(self):\n        # 调用父类的初始化函数\n        super(Model,self).__init__()\n        # 实例变量，定义卷积层\n        self.conv1 = nn.Conv2d(in_channels = 1,out_channels = 20,kernel_size = 5)\n        self.conv2 = nn.Conv2d(in_channels = 20,out_channels = 20,kernel_size = 5)\n\n    # 前向传播函数\n    def forward(self,x):\n        # 两层卷积+非线性激活层（relu函数）\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        return x  # 返回结果","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T05:30:56.817084Z","iopub.execute_input":"2025-10-16T05:30:56.817433Z","iopub.status.idle":"2025-10-16T05:31:00.433000Z","shell.execute_reply.started":"2025-10-16T05:30:56.817407Z","shell.execute_reply":"2025-10-16T05:31:00.432437Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### 2.nn.Sequential\nnn.Sequential是一个顺序容器，模块按照它们在序列中的顺序被依次执行，用于将多个模块按顺序组合起来。\n\n前向传播时，输入数据依次通过序列中的每个模块，因此无需再另外定义前向传播函数。\n\n模块的添加方式可以是通过传入一个有序字典（OrderedDict）或直接传入模块列表。适合快速构建简单的序列模型。","metadata":{}},{"cell_type":"code","source":"# 定义一个序列，依次插入神经网络的各个层\n# 无需定义前向传播机制，自动按顺序运算\nmodel = nn.Sequential(\n          nn.Conv2d(1,20,5),\n          nn.ReLU(),\n          nn.Conv2d(20,64,5),\n          nn.ReLU()\n        )\n\n# 也可以传入有序字典OrderedDict，与上面的代码结果相同\nfrom collections import OrderedDict\nmodel = nn.Sequential(OrderedDict([\n          ('conv1', nn.Conv2d(1,20,5)),\n          ('relu1', nn.ReLU()),\n          ('conv2', nn.Conv2d(20,64,5)),\n          ('relu2', nn.ReLU())\n        ]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T05:31:42.513654Z","iopub.execute_input":"2025-10-16T05:31:42.514362Z","iopub.status.idle":"2025-10-16T05:31:42.537905Z","shell.execute_reply.started":"2025-10-16T05:31:42.514338Z","shell.execute_reply":"2025-10-16T05:31:42.537332Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### 3.nn.ModuleList\nnn.ModuleList是一个用于保存子模块的列表，提供类似列表的操作（如添加append、索引访问__getitem__、迭代等），但没有类似nn.Sequential那样自动执行前向传播的功能。","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # 动态创建层序列\n        self.conv_layers = nn.ModuleList([\n            nn.Conv2d(3, 6, 5),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(6, 16, 5),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n        ])\n        # 全连接层\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(16 * 4 * 4, 120),\n            nn.ReLU(),\n            nn.Linear(120, 10)\n        )\n    \n    def forward(self, x):\n        # 顺序执行所有卷积层\n        for layer in self.conv_layers:\n            x = layer(x)\n        return self.classifier(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T05:31:49.442244Z","iopub.execute_input":"2025-10-16T05:31:49.442944Z","iopub.status.idle":"2025-10-16T05:31:49.447989Z","shell.execute_reply.started":"2025-10-16T05:31:49.442922Z","shell.execute_reply":"2025-10-16T05:31:49.447189Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### 4.nn.ModuleDict\nnn.ModuleDict本质是一个命名模块字典，具有类似字典的操作（键值对访问），与顺序无关，适用于多分支模型。","metadata":{}},{"cell_type":"code","source":"class ModuleDict(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # 按功能命名组织层\n        self.features = nn.ModuleDict({\n            'conv1': nn.Conv2d(3, 6, 5),\n            'relu1': nn.ReLU(),\n            'pool1': nn.MaxPool2d(2),\n            'conv2': nn.Conv2d(6, 16, 5),\n            'relu2': nn.ReLU(),\n            'pool2': nn.MaxPool2d(2)\n        })\n        self.classifier = nn.ModuleDict({\n            'flatten': nn.Flatten(),\n            'fc1': nn.Linear(16 * 4 * 4, 120),\n            'act': nn.ReLU(),\n            'fc2': nn.Linear(120, 10)\n        })\n    \n    def forward(self, x):\n        # 按顺序调用特征层\n        for layer in ['conv1', 'relu1', 'pool1', 'conv2', 'relu2', 'pool2']:\n            x = self.features[layer](x)\n        # 按顺序调用分类器\n        for op in ['flatten', 'fc1', 'act', 'fc2']:\n            x = self.classifier[op](x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T05:31:53.490959Z","iopub.execute_input":"2025-10-16T05:31:53.491236Z","iopub.status.idle":"2025-10-16T05:31:53.497192Z","shell.execute_reply.started":"2025-10-16T05:31:53.491214Z","shell.execute_reply":"2025-10-16T05:31:53.496428Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### 5.总结\n- nn.Module是**基类**：是所有模型模块的基础，定义前向逻辑并管理参数/状态，适用任意复杂模型（分支/跳跃连接）。\n- nn.Sequential是**顺序管道**：自动按添加顺序执行层，适用于线性结构模型，简化前向实现。\n- nn.ModuleList是**动态容器**：存储层列表供迭代/索引访问，适用动态层数模型（如RNN堆叠），可append层但需手动前向。\n- nn.ModuleDict是**命名字典**：按键名（字符串）组织层，适用多分支/条件选择结构（如多任务头），支持灵活访问与重组。\n\n**内在联系**：\n- 继承关系：Sequential/ModuleList/ModuleDict 都是 Module 的子类\n- 协同工作：复杂模型中嵌套使用（如 Module 包含 ModuleDict 管理多头、Sequential管理模块等等）","metadata":{}},{"cell_type":"markdown","source":"## 二、卷积层\n使用nn.Conv2d函数定义二维的卷积层（适用于图像），类的结构如下：\n\nCLASS torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n\n- **in_channels**：输入通道数（如RGB图像为3，黑白图像为1）\n- **out_channels**：输出通道数（输出的卷积核数量）\n- **kernel_size**：卷积核的大小，为整数（正方形）或（height,weight）\n- **stride**：步幅大小，整数或 (h_stride, w_stride)\n- **padding**：填充数量，整数（上下左右填充数量相同）或（h_pad,w_pad）表示上下相同、左右相同。\n- **dilation**：卷积核元素间的空洞间距（控制核膨胀）\n- **groups**：输入/输出通道的分组数（1=标准卷积）\n- **bias**：是否添加可学习的偏置项\n- **padding_mode**：填充模式，默认为'zero'，除此之外还有'reflect'（镜像填充）、'replicate'（重复边缘值）和'circular'（循环填充）\n- **device**：参数储存在CPU/GPU\n- **dtype**：参数数据类型\n## 三、池化层\n池化层包括最大池化MaxPool2d和平均池化AvgPool2d，以MaxPool2d类为例，参数结构如下：\n\nCLASS torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n\n- kernel_size：滑动窗口（池化核）尺寸，整数（方形核）或元组 (height, width)\n- stride：窗口移动步长\n- padding：填充个数\n- dilation：池化核元素间隔（扩大感受野）\n- return_indices：是否返回最大值位置索引，默认False\n- ceil_mode：尺寸计算方式，默认False，向下取整","metadata":{}},{"cell_type":"markdown","source":"## 四、数据获取与加载\n### 1. Dataset\nDataset旨在提供一种方式，获取数据集及其对应的真实label值，以便为模型提供合适的输入格式。Dataset是一个类，可以通过dir()访问类的实例方法，通过help()查看类的定义和使用方法。\n\n### 2.DataLoader\nDataset负责指定一个数据集，而DataLoader则负责将数据集读取、并加载到神经网络内。\nDataLoader类包括的参数有：\n\nCLASS torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=None, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, multiprocessing_context=None, generator=None, *, prefetch_factor=None, persistent_workers=False, pin_memory_device='', in_order=True)\n\n- **dataset**：要加载的数据集对象（Dataset子类实例）\n- **batch_size**：每个批次的样本数，神经网络常见的超参数之一（默认为1）\n- **shuffle**：是否在每个epoch前打乱数据顺序，一般设为True（默认为False）\n- **sampler**：自定义采样对象，与shuffle互斥\n- **batch_sampler**：返回整个批次索引的采样器（替代batch_size+sampler）\n- **number_workers**：数据加载子进程数（0=主进程加载，>0=并行加载），默认为0\n- **drop_last**：是否丢弃最后不足batch_size的剩余样本（默认False保留）\n- prefetch_factor：每个worker预取的批次数量（默认=2）\n- persistent_workers：是否保持worker进程存活（减少进程重建开销）\n- pin_memory：是否将数据复制到锁页内存（加速GPU传输）\n- pin_memory_device​​：指定锁页内存设备（如‘cuda’）\n- collate_fn​​：自定义批次样本组合函数（处理不规则数据）\n- worker_init_fn​​：worker进程初始化函数（设置随机种子等）\n- timeout​​：数据加载超时时间（秒，默认0=无限等待）\n- multiprocessing_context​​：多进程启动方式（‘spawn’/‘fork’）\n- generator​​：指定随机数生成器（控制shuffle的随机性）\n- in_order​​：分布式场景下是否按顺序返回数据（默认True避免性能开销）","metadata":{}},{"cell_type":"code","source":"# torch.utils.data包含了处理数据的一般工具包\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torchvision\nimport torchvision.transforms as transforms\n\n\n# 定义存储位置及批次大小\ndata_dir = '/kaggle/working'\nbatch_size = 256\n\n# 加载CIFAR-10数据集\ntrain_dataset = torchvision.datasets.CIFAR10(\n    root=data_dir,\n    train=True,\n    download=True\n)\n\ntest_dataset = torchvision.datasets.CIFAR10(\n    root=data_dir,\n    train=False,\n    download=True\n)\n\n\n# 创建数据加载器\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T05:35:24.178012Z","iopub.execute_input":"2025-10-16T05:35:24.178270Z","iopub.status.idle":"2025-10-16T05:35:40.735046Z","shell.execute_reply.started":"2025-10-16T05:35:24.178251Z","shell.execute_reply":"2025-10-16T05:35:40.734413Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 170M/170M [00:13<00:00, 13.0MB/s] \n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## 五、Torchvision的使用\ntorchvision是Pytorch应用于计算机视觉领域的**扩展库**，主要提供：\n\n- 流行的数据集：如MNIST, CIFAR10, ImageNet，可以直接通过torchvision库导入数据；\n- 常见的模型架构：如AlexNet, ResNet, VGG，以及预训练权重；\n- 图像变换和增强操作：用于数据预处理和数据增强；\n- 工具函数（如绘制边界框、网格保存图像等）\n### 1.torchvision导入数据\n可以通过dir()查看内置数据集：dir(torchvision.datasets)。以CIFAR10为例：\n\nCLASS torchvision.datasets.CIFAR10(root: Union[str, Path], train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)\n\n- **root**：数据存储路径\n- **train**：是否为训练集\n- **transform**：数据预处理方法，默认为None\n- **target_transform**：标签预处理变换，默认为None\n- **download**：是否下载数据集，默认为False，同一路径下不会重复下载\n### 2.transforms.Compose数据预处理\ntorchvision库的transforms.Compose专门用于数据预处理和数据增强，常用的方法包括：\n\n张量转换及标准化：\n- **transforms.ToTensor()**：PIL→Tensor，将图片转换为张量格式\n- **transforms.Normalize()**：张量标准化，输入各通道mean、std，列表格式\n- **transforms.Resize()**：尺寸调整，设定size（int/(h,w))\n- **transforms.CenterCrop()**：中心裁剪，设定裁剪size\n- **transforms.RandomCrop()**：随机裁剪，设定裁剪大小size(int/(h,w))、填充padding\n- **transforms.ColorJitter()**：亮度brightness、对比度contrast、饱和度saturation、色相偏移hue\n- **transforms.GausssianBlur()**：随机选定高斯模糊核模糊图像，参数包括kernel_size、sigma（模糊程度的方差）\n- **transforms.RandomHorizontalFlip()**：随机水平翻转\n- **transforms.RandomRotation()**：随机角度的旋转","metadata":{}},{"cell_type":"code","source":"import torchvision\nimport torchvision.transforms as transforms\n\n# 数据处理\ntransform = transforms.Compose([\n    transforms.Resize(256),                     # 尺寸调整\n    transforms.RandomCrop(224),                 # 随机裁剪\n    transforms.RandomHorizontalFlip(p=0.5),     # 随机水平翻转\n    transforms.ColorJitter(\n        brightness=0.2,                        # 亮度调整幅度\n        contrast=0.2,                          # 对比度调整幅度\n        saturation=0.2,                        # 饱和度调整幅度\n        hue=0.02 ),                              # 色相偏移范围(-0.5,0.5)\n    transforms.ToTensor(),                     # 转为Tensor\n    transforms.Normalize(                      # 归一化\n        mean=[0.485, 0.456, 0.406],           # 通道均值（分别计算三个通道的均值）\n        std=[0.229, 0.224, 0.225]             # 通道标准差（分别计算三个通道的标准差）\n    )])\n\n# 加载CIFAR-10数据集\ndata_dir = \"/kaggle/working\"\ntrain_dataset = torchvision.datasets.CIFAR10(\n    root=data_dir,\n    train=True,\n    download=True,\n    transform=transform\n)\n\ntest_dataset = torchvision.datasets.CIFAR10(\n    root=data_dir,\n    train=False,\n    download=True,\n    transform=transform\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T05:36:09.121680Z","iopub.execute_input":"2025-10-16T05:36:09.122258Z","iopub.status.idle":"2025-10-16T05:36:10.595678Z","shell.execute_reply.started":"2025-10-16T05:36:09.122234Z","shell.execute_reply":"2025-10-16T05:36:10.595128Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nhelp(Dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T05:36:14.241576Z","iopub.execute_input":"2025-10-16T05:36:14.241856Z","iopub.status.idle":"2025-10-16T05:36:14.248685Z","shell.execute_reply.started":"2025-10-16T05:36:14.241835Z","shell.execute_reply":"2025-10-16T05:36:14.248134Z"}},"outputs":[{"name":"stdout","text":"Help on class Dataset in module torch.utils.data.dataset:\n\nclass Dataset(typing.Generic)\n |  An abstract class representing a :class:`Dataset`.\n |  \n |  All datasets that represent a map from keys to data samples should subclass\n |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n |  data sample for a given key. Subclasses could also optionally overwrite\n |  :meth:`__len__`, which is expected to return the size of the dataset by many\n |  :class:`~torch.utils.data.Sampler` implementations and the default options\n |  of :class:`~torch.utils.data.DataLoader`. Subclasses could also\n |  optionally implement :meth:`__getitems__`, for speedup batched samples\n |  loading. This method accepts list of indices of samples of batch and returns\n |  list of samples.\n |  \n |  .. note::\n |    :class:`~torch.utils.data.DataLoader` by default constructs an index\n |    sampler that yields integral indices.  To make it work with a map-style\n |    dataset with non-integral indices/keys, a custom sampler must be provided.\n |  \n |  Method resolution order:\n |      Dataset\n |      typing.Generic\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __add__(self, other: 'Dataset[_T_co]') -> 'ConcatDataset[_T_co]'\n |  \n |  __getitem__(self, index) -> +_T_co\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables\n |  \n |  __weakref__\n |      list of weak references to the object\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __annotations__ = {}\n |  \n |  __orig_bases__ = (typing.Generic[+_T_co],)\n |  \n |  __parameters__ = (+_T_co,)\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from typing.Generic:\n |  \n |  __class_getitem__(params)\n |      Parameterizes a generic class.\n |      \n |      At least, parameterizing a generic class is the *main* thing this method\n |      does. For example, for some generic class `Foo`, this is called when we\n |      do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n |      \n |      However, note that this method is also called when defining generic\n |      classes in the first place with `class Foo(Generic[T]): ...`.\n |  \n |  __init_subclass__(*args, **kwargs)\n |      This method is called when a class is subclassed.\n |      \n |      The default implementation does nothing. It may be\n |      overridden to extend subclasses.\n\n","output_type":"stream"}],"execution_count":20}]}